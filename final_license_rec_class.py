# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19XRqjEocN3xiCX-8PMRVRdkt4vpOMZrs
"""

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from PIL import Image, UnidentifiedImageError
from torchvision import transforms
from tqdm import tqdm

# === Paths ===
base_path = ''
train_path = os.path.join(base_path, 'train/train')
val_path = os.path.join(base_path, 'val/val')
train_list_path = os.path.join(base_path, 'train/train_list.txt')
val_list_path = os.path.join(base_path, 'val/val_list.txt')
model_save_path = 'best_model.pth'

# === Class Names and Mapping ===
class_names = sorted([
    "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA",
    "MA", "MD", "ME", "MI", "MN", "MO", "MP", "MS", "MT", "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
    "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT", "WA", "WI", "WV", "WY"
])
class_to_idx = {abbr: i for i, abbr in enumerate(class_names)}
num_classes = len(class_names)

# === Device ===
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
from torchvision.transforms import functional as TF

class ResizeWithPadding:
    def __init__(self, target_size):
        self.target_size = target_size  # (H, W)

    def __call__(self, img):
        w, h = img.size
        scale = min(self.target_size[1] / w, self.target_size[0] / h)
        new_w, new_h = int(w * scale), int(h * scale)
        img = img.resize((new_w, new_h), Image.BILINEAR)

        pad_left = (self.target_size[1] - new_w) // 2
        pad_top = (self.target_size[0] - new_h) // 2
        pad_right = self.target_size[1] - new_w - pad_left
        pad_bottom = self.target_size[0] - new_h - pad_top

        img = TF.pad(img, (pad_left, pad_top, pad_right, pad_bottom), fill=0)
        return img



# === Transforms ===
train_transform = transforms.Compose([
    ResizeWithPadding((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.2, 0.2, 0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    ResizeWithPadding((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# === Dataset
class LicensePlateDataset(Dataset):
    def __init__(self, folder, list_file, class_to_idx, transform=None):
        self.folder = folder
        self.transform = transform
        self.class_to_idx = class_to_idx
        self.samples = []

        # Load plate labels
        self.plate_dict = {}
        with open(list_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 2:
                    img_name = os.path.basename(parts[0]).lower()
                    plate_text = parts[1].upper()
                    self.plate_dict[img_name] = plate_text

        # Match images to labels
        for fname in sorted(os.listdir(folder)):
            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
                abbr = fname[:2].upper()
                fname_lower = fname.lower()
                if abbr in class_to_idx and fname_lower in self.plate_dict:
                    path = os.path.join(folder, fname)
                    state_label = class_to_idx[abbr]
                    plate_label = self.plate_dict[fname_lower]
                    self.samples.append((path, state_label, plate_label))
                else:
                    print(f"⚠️ Skipping {fname}: not in label file or invalid state abbreviation")

        print(f"✅ Loaded {len(self.samples)} samples from {folder}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, state_label, plate_text = self.samples[idx]
        try:
            image = Image.open(path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            return image, state_label, plate_text
        except (UnidentifiedImageError, FileNotFoundError) as e:
            print(f"❌ Error loading {path}: {e}")
            return self.__getitem__((idx + 1) % len(self.samples))  # Try next item to avoid crash

# === Instantiate Datasets
# === Instantiate Datasets
train_dataset = LicensePlateDataset(train_path, train_list_path, class_to_idx, transform=train_transform)
val_dataset = LicensePlateDataset(val_path, val_list_path, class_to_idx, transform=val_transform)




data_loaders = {
    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, drop_last=True),
    'test': DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True)
}

from torchsummary import summary
from torchvision import models
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm
import torch.nn as nn
import torch
import torch.nn.functional as F

# === Define class names (ensure this is defined early)
class_names = sorted([
    "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA",
    "MA", "MD", "ME", "MI", "MN", "MO", "MP", "MS", "MT", "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
    "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT", "WA", "WI", "WV", "WY"
])
num_classes = len(class_names)

# === Model Setup
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
summary(model, input_size=(3, 224, 224))

# === Freeze early layers
for param in model.parameters():
    param.requires_grad = False

# === Fine-tune deeper layers
for name, param in model.named_parameters():
    if 'layer4' in name or 'fc' in name:
        param.requires_grad = True

# === Replace classification head
model.fc = nn.Sequential(
    nn.Linear(2048, 512),
    nn.BatchNorm1d(512),
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),
    nn.Linear(512, 128),
    nn.BatchNorm1d(128),
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),
    nn.Linear(128, num_classes)
)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# === Training setup
params_to_update = [p for p in model.parameters() if p.requires_grad]
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
optimizer = torch.optim.AdamW(params_to_update, lr=1e-3, weight_decay=1e-4)
scheduler = CosineAnnealingLR(optimizer, T_max=10)

train_losses, test_losses, train_acc, test_acc = [], [], [], []
best_acc = 0
num_epochs = 25

# === Train one epoch
def train_one_epoch(model, loader):
    model.train()
    correct, total, running_loss = 0, 0, 0
    loop = tqdm(loader, desc="🚂 Training", leave=True)
    for images, labels, _ in loop:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        preds = outputs.argmax(1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

        acc = 100 * correct / total
        loop.set_postfix(loss=loss.item(), acc=f"{acc:.2f}%")

    train_losses.append(running_loss / total)
    train_acc.append(100 * correct / total)

# === Evaluate one epoch
def evaluate(model, loader):
    model.eval()
    correct, total, running_loss = 0, 0, 0
    all_preds = []
    loop = tqdm(loader, desc="🧪 Evaluating", leave=True)
    with torch.no_grad():
        for images, labels, _ in loop:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)
            preds = outputs.argmax(1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # ✅ Get predicted state names for debugging
            predicted_states = [class_names[i] for i in preds.tolist()]
            all_preds.extend(predicted_states)

            acc = 100 * correct / total if total > 0 else 0
            loop.set_postfix(loss=loss.item(), acc=f"{acc:.2f}%")

    test_losses.append(running_loss / total)
    acc = 100 * correct / total
    test_acc.append(acc)

    # ✅ Optionally print a few predictions
    print("Sample predictions:", all_preds[:5])
    return acc

# === Training Loop
for epoch in range(num_epochs):
    print(f"\n🌱 Epoch {epoch + 1}/{num_epochs}")
    train_one_epoch(model, data_loaders['train'])
    acc = evaluate(model, data_loaders['test'])
    print(f"✅ Test Accuracy: {acc:.2f}%")

    scheduler.step()
    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), 'best_model.pth')
        print("💾 Best model saved!")





import os
import csv
import logging
import numpy as np
from matplotlib import pyplot as plt
from paddleocr import PaddleOCR, draw_ocr
from ppocr.utils.logging import get_logger as ppocr_get_logger



# === Load Ground Truth Labels
def label_reader(file_path):
    with open(file_path) as f:
        return {row[0]: row[1] for row in csv.reader(f)}

true_labels = label_reader('groundtruth.csv')

# === OCR Prediction Function
def predict(img_path, reader):
    result = reader.ocr(img_path)
    if not result or not result[0]:
        return "0", 0.0

    predictions = []
    for line in result[0]:
        bbox = line[0]
        text, conf = line[1]

        try:
            # Make sure bbox is 4 points with 2D coordinates
            if not (len(bbox) == 4 and all(isinstance(pt, list) and len(pt) == 2 for pt in bbox)):
                continue

            # Convert coordinates to floats
            x0, y0 = map(float, bbox[0])
            x1, y1 = map(float, bbox[1])
            x2, y2 = map(float, bbox[2])
            x3, y3 = map(float, bbox[3])

            area = abs(x1 - x0) * abs(y2 - y1)
            y_center = np.mean([y0, y1, y2, y3])

            predictions.append((bbox, text, area, y_center, conf))
        except Exception:
            continue

    if not predictions:
        return "0", 0.0

    main = max(predictions, key=lambda x: x[2])
    pred_text, pred_conf = main[1], main[4]
    return pred_text, float(pred_conf)

# Evaluate all images
#all_images = glob.glob(os.path.join(
#    'val/',
#    '*.png'
#))

#incorrect_samples = []
#num_correct = 0
#total_num = len(all_images)

#for img in all_images:
#    pred_label, confidence = predict(img, ocr)
#    pred_label = "".join(ch.upper() for ch in pred_label if ch.isalnum())

#    img_id = img.split('/')[-1]
#    if pred_label == true_labels[img_id]:
#        num_correct += 1
#    else:
#        incorrect_samples.append((img, pred_label, confidence))

#print('✅ Final Accuracy: %.2f%% (%d/%d)' % ((num_correct / total_num) * 100, num_correct, total_num))











import os
import re
import torch
import pandas as pd
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms, models
import string

# === Device & Paths
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
val_path = "val/val"
state_model_path = "best_model.pth"

# === Constants
class_names = sorted([
    "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA",
    "MA", "MD", "ME", "MI", "MN", "MO", "MP", "MS", "MT", "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
    "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT", "WA", "WI", "WV", "WY"
])

# === Load State Classifier (ResNet50)
state_model = models.resnet50(weights=None)
state_model.fc = torch.nn.Sequential(
    torch.nn.Linear(2048, 512),
    torch.nn.BatchNorm1d(512),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.3),
    torch.nn.Linear(512, 128),
    torch.nn.BatchNorm1d(128),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.3),
    torch.nn.Linear(128, len(class_names))
)
state_model.load_state_dict(torch.load(state_model_path, map_location=device))
state_model = state_model.to(device).eval()


# === Transforms
state_tf = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])



results = []
for fname in sorted(os.listdir(val_path)):
    if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):
        continue

    true_state = fname[:2].upper()
    path = os.path.join(val_path, fname)
    try:
        img = Image.open(path).convert("RGB")
    except Exception:
        continue

    try:
        # === OCR Prediction
        plate, ocr_conf = predict(path, ocr)
        plate = "".join(ch.upper() for ch in plate if ch.isalnum())

        # === State Prediction
        state_tensor = state_tf(img).unsqueeze(0).to(device)
        with torch.no_grad():
            state_logits = state_model(state_tensor)
            probs = F.softmax(state_logits, dim=1)
            conf, pred_idx = torch.max(probs, dim=1)
            pred_state = class_names[pred_idx.item()]
            state_conf = conf.item()

        results.append({
            "image": fname,
            "true_state": true_state,
            "predicted_state": pred_state,
            "correct_state": pred_state == true_state,
            "state_confidence": round(state_conf, 3),
            "plate_number": plate,
            "ocr_confidence": round(ocr_conf, 3)
        })

    except Exception as e:
        continue

# === Output
df = pd.DataFrame(results)
df